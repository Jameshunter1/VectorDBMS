---
trigger: always_on
---

# Vectis Vector Database  
## AI System Instructions (Authoritative and Mandatory)

---

## 1. Project Context

You are working on **Vectis**, a **disk-oriented, AI-native vector database engine**.

You are using:
- **C++20**
- **Explicit disk-backed storage**
- **Manual memory management**
- **Explicit concurrency control**
- **Production-grade database internals**

You are not building:
- An in-memory database
- A prototype or toy system
- A wrapper over RocksDB, SQLite, LevelDB, or similar engines

---

## 2. Global Assumptions (Always True)

You will assume:
- The database **lives on disk**
- DRAM is **only a cache**
- The OS page cache is **not used**
- Power loss and crashes **can occur at any instruction**
- Correctness and durability **come before performance**

---

## 3. Storage Model Rules

You are using:
- **Fixed-size 16KB pages**
- **512-byte aligned buffers**
- **O_DIRECT file I/O**
- **Slotted page layout**

You will:
- Treat a page as the **only persistence unit**
- Store all data and metadata **inside pages**
- Map `PageID → disk offset` **only** inside `DiskManager`
- Flush pages **only after WAL is durable**
- Store `PageID`, `PageLSN`, and slot directory in the page header

You will not:
- Use mmap
- Store records outside pages
- Rely on the OS for caching or eviction
- Perform unaligned or partial I/O

---

## 4. Buffer Pool Rules

You are using:
- A **central BufferPoolManager**
- **LRU-K eviction (K = 2)**

You will:
- Track page accesses explicitly
- Evict pages using **LRU-K semantics**
- Protect hot pages from scan pollution
- Clearly document ownership and locking for every shared structure

You will not:
- Use naive LRU
- Use reference counts as an eviction policy
- Introduce global locks in hot paths
- Hide synchronization inside containers

---

## 5. Durability and Recovery Rules

You are using:
- **Write-Ahead Logging (WAL)**
- **ARIES recovery protocol**
- **STEAL / NO-FORCE buffer policy**

You will:
- Write WAL records **before** flushing dirty pages
- Enforce `pageLSN <= flushedLSN` before disk writes
- Implement **Analysis → Redo → Undo** exactly
- Use **fuzzy checkpoints**
- Assume crashes during any phase of execution

You will not:
- Skip WAL for performance reasons
- Assume clean shutdowns
- Partially implement ARIES
- Allow page writes without WAL validation

---

## 6. Roadmap Awareness (Mandatory)

You will always reason about **which roadmap year applies**.

### Year 1 (Foundational Storage)

You will use:
- Synchronous disk I/O
- Explicit mutex-based locking
- Hash-table PageID lookups
- Slotted pages
- LRU-K eviction

You will not use:
- io_uring
- Pointer swizzling
- userfaultfd or vmcache
- SIMD intrinsics
- GPU acceleration

### Year 2 and Later

You will:
- Introduce features **only if explicitly justified by the roadmap**
- Leave extension points for future systems
- Add TODOs instead of partial implementations

You will not:
- Implement future systems early
- Mix roadmap phases in production code

---

## 7. Memory Management Rules

You are using:
- Explicit ownership semantics
- Bounded allocations
- Aligned buffers for all I/O

You will:
- Avoid hidden heap allocations in hot paths
- Use fixed-size or reserved containers
- Align all I/O buffers to at least 512 bytes
- Clearly document lifetimes and ownership

You will not:
- Use raw `new` or `delete`
- Rely on implicit reallocations
- Allocate memory inside tight loops
- Leak ownership through APIs

---

## 8. Error Handling Rules

You are using:
- Explicit error codes or status objects

You will:
- Handle all error paths explicitly
- Use assertions only for invariants
- Treat I/O failures as recoverable events

You will not:
- Use exceptions in hot paths
- Use exceptions in disk I/O
- Use exceptions in buffer management
- Use exceptions for control flow

---

## 9. Concurrency Rules

You will:
- Assume many-core contention
- Allow readers to scale without blocking when possible
- Allow writers to block in a bounded manner
- Document memory ordering and synchronization assumptions

You will not:
- Introduce unbounded contention
- Rely on global locks
- Ignore false sharing or cache-line contention

---

## 10. Observability Rules

You will expose:
- Cache hit / miss counters
- Eviction metrics
- Retry and contention metrics
- Latency metrics where applicable

You will not:
- Log inside tight loops
- Allocate memory during logging
- Emit verbose logs on hot paths

---

## 11. AI Output Expectations

When generating code, you will:
- State which **roadmap year** the code targets
- Explain **why** a design choice exists
- Prefer clarity over cleverness
- Assume the code will be debugged after a crash

If uncertain, you will:
- Default to the simplest correct design
- Ask which roadmap year applies
- Avoid speculative optimizations

---

## 12. Absolute Rejections

You will explicitly reject suggestions involving:
- SQLite, RocksDB, LevelDB, or similar engines
- mmap-based storage engines
- HTTP/JSON for vector transport
- Garbage-collected languages
- “Optimize later” arguments

---

## 13. Guiding Principle

If the design would not survive a database systems conference review,
**it does not belong in Vectis**.
